# Sistem Prediksi Dropout Mahasiswa
**Implementasi Data Mining untuk Early Warning System Akademik**

## Anggota Kelompok
- **Davi Sulaiman** (G1A022001)
- **Rafi Afrian Al-Haritz** (G1A022035)  
- **Alif Nurhidayat** (G1A022073)

---

## Dashboard Prototipe Sistem
**üåê Link Dashboard:** http://KillerKing93-UAS-Penambangan-Data.hf.space

**Kredensial Akses:**
- **Username:** admin
- **Password:** admin123

![tampilan_dashboard](assets/tampilan_dashboard.png)

**Gambar: tampilan_dashboard** 

---

## Daftar Isi
1. [Overview Sistem](#overview-sistem)
2. [Metode Data Mining & Justifikasi](#metode-data-mining--justifikasi)
3. [Proses CRISP-DM Lengkap](#proses-crisp-dm-lengkap)
4. [Teknik Preprocessing Data](#teknik-preprocessing-data)
5. [Strategi Evaluasi Model](#strategi-evaluasi-model)
6. [Struktur Project](#struktur-project)
7. [Instalasi dan Setup](#instalasi-dan-setup)
8. [Penggunaan Sistem](#penggunaan-sistem)
9. [Pengembangan Sistem Lanjutan](#pengembangan-sistem-lanjutan)

---

## Overview Sistem

### Cerita Sistem
Program studi informatika mendapatkan sebuah tantangan dari rektor akademik, yang dimana seorang rektor ini merasa cemas melihat mahasiswa berprestasi tiba-tiba mengalami penurunan akademik drastis. "Seandainya ada sistem yang bisa memperingatkan sejak dini sebelum mahasiswa benar-benar dropout," Program studi informatika berpikir bagaimana membuat sistem tersebut sambil melihat data 285 mahasiswa TI di mana 150 mahasiswa (52.6%) teridentifikasi berisiko dropout.

Maka lahirlah sistem prediksi dropout berbasis machine learning ini. Dengan menganalisis 22 variabel komprehensif mulai dari demografi, performa akademik, pola kehadiran, hingga aktivitas digital learning, sistem dapat memberikan early warning dengan akurasi 100% menggunakan Random Forest.

**Penjelasan Teknis:**
Sistem ini mengimplementasikan ensemble learning untuk mengidentifikasi mahasiswa berisiko dropout berdasarkan data historis 285 mahasiswa angkatan 2022-2024. Dengan pipeline CRISP-DM yang komprehensif, sistem mampu melakukan prediksi real-time dan memberikan rekomendasi intervensi yang dipersonalisasi untuk setiap mahasiswa.

---

## Metode Data Mining & Justifikasi

### **1. Random Forest (Metode Utama) - Akurasi 100%**

**Cerita Pemilihan:**
Seperti seorang dokter yang berkonsultasi dengan panel ahli sebelum diagnosis, Random Forest mengombinasikan "pendapat" dari 100 decision tree untuk menghasilkan prediksi yang akurat. Setiap tree memberikan "suara" berdasarkan subset data yang berbeda, lalu mayoritas suara menentukan hasil akhir.

![Architecture](assets/random_forest_architecture.png)

**Gambar: Diagram Random Forest Architecture** 

**Justifikasi Teknis:**

**A. Keunggulan untuk Dataset Dropout:**
- **Handling Mixed Data Types**: Mampu menangani variabel numerik (IPK, kehadiran) dan kategorik (jenis kelamin, asal daerah) secara bersamaan
- **Feature Importance**: Mengidentifikasi variabel paling berpengaruh terhadap dropout risk
- **Robust to Outliers**: Tahan terhadap mahasiswa dengan profil akademik yang ekstrem
- **No Overfitting**: Ensemble method mengurangi risiko overfitting pada dataset 285 records

**B. Perbandingan dengan Algoritma Lain:**

![model_comparasion](assets/model_comparasion.png)

**Gambar: Model Comparison** 

| Model | Accuracy | Precision | Recall | F1-Score |
|-------|----------|-----------|---------|----------|
| **Random Forest** | **100.00%** | **100.00%** | **100.00%** | **100.00%** |
| AdaBoost | 98.25% | 98.31% | 98.25% | 98.25% |
| XGBoost | 94.74% | 95.28% | 94.74% | 94.75% |
| Decision Tree | 94.74% | 95.28% | 94.74% | 94.75% |
| Gradient Boosting | 94.74% | 95.28% | 94.74% | 94.75% |
| K-Nearest Neighbors | 75.44% | 77.06% | 75.44% | 74.61% |

**C. Konfigurasi Optimal:**
```python
RandomForestClassifier(
    n_estimators=100,        # 100 trees untuk stabilitas
    random_state=42,         # Reproducible results
    n_jobs=-1               # Parallel processing
)
```

### **2. Algoritmo Pendukung Berdasarkan Literatura**

Berdasarkan systematic literature review oleh Schr√∂er et al. (2021), CRISP-DM tetap menjadi de-facto standard dalam proyek data mining. Studi mereka menganalisis 24 penelitian dan menunjukkan bahwa Random Forest adalah salah satu algoritma yang paling sering digunakan dalam implementasi CRISP-DM.

**AdaBoost (Runner-up - 98.25% accuracy):**
- Excellent untuk sequential learning
- Fokus pada misclassified instances
- Complementary approach to Random Forest

**XGBoost (94.74% accuracy):**
- Gradient boosting optimization
- Efficient untuk large datasets
- Built-in regularization

---

## Proses CRISP-DM Lengkap

### **Phase 1: Business Understanding**

**Cerita Bisnis:**
Program Studi Teknik Informatika menghadapi tantangan dropout rate yang tinggi. Dari 285 mahasiswa aktif, 150 mahasiswa (52.6%) teridentifikasi berisiko dropout. Dampaknya tidak hanya merugikan mahasiswa dan keluarga, tetapi juga menurunkan akreditasi program studi dan reputasi institusi.

**Objektif Bisnis:**
- Mengurangi dropout rate dari 52.6% menjadi < 30% dalam 2 tahun
- Implementasi early warning system untuk intervensi tepat waktu
- Meningkatkan success rate dan student satisfaction

**Kriteria Sukses:**
- Akurasi prediksi ‚â• 90%
- Response time < 2 detik untuk real-time prediction
- User adoption rate ‚â• 80% dari staff akademik

### **2. Data Understanding**

**Karakteristik Dataset:**

![Data_Understanding](assets/data_understanding.png)

**Gambar: Dataset Overview Infographic** 

```python
# Data Overview
dataset_info = {
    "total_records": 285,
    "total_features": 25,
    "target_distribution": {
        "tidak_berisiko": 135, "persentase": "47.4%",
        "berisiko_dropout": 150, "persentase": "52.6%"
    },
    "data_quality": {
        "missing_values": "Minimal (hanya semester_dropout 98.6%)",
        "duplicates": 0,
        "quality_score": "Excellent"
    }
}
```

**Exploratory Data Analysis:**

![correlation_matrix](assets/correlation_matrix.png)

**Gambar: Correlation Heatmap** 

```python
# Correlation Analysis
correlation_matrix = df_cleaned.corr(numeric_only=True)
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Feature Correlation Matrix")
```

![Target_Distribution](assets/status_rate.png)

**Gambar: Target Distribution Chart** 

```python
# Target Distribution Analysis
dropout_rate = df['flag_peringatan_dini'].value_counts(normalize=True) * 100
sns.barplot(x=dropout_rate.index.astype(str), y=dropout_rate.values)
plt.title("Distribusi Risiko Dropout (%)")
```

**Key Findings dari Analisis:**
- IPK rata-rata mahasiswa berisiko: 2.8 vs mahasiswa aman: 3.4
- Kehadiran rata-rata berbeda signifikan: 68% vs 89%
- Penghasilan keluarga rendah berkorelasi dengan risiko tinggi

Sesuai dengan temuan Biswas et al. (2022) dalam studi stroke prediction, variabel demografis dan behavioral menunjukkan korelasi yang signifikan dengan outcome prediction. Penelitian mereka mencapai akurasi 99.99% dengan Support Vector Machine, yang mendukung validitas pendekatan ensemble learning yang kami gunakan.

### **Phase 3: Data Preparation**

**Cerita Preprocessing:**
Data mentah seperti bahan masakan yang perlu diolah sebelum dimasak. Proses preprocessing mengubah data kategorikal menjadi numerik, menstandarisasi skala variabel, dan memastikan semua fitur siap untuk "dicerna" oleh algoritma machine learning.

**A. Feature Selection & Cleaning:**
```python
# Remove irrelevant columns
df_cleaned = df.copy()
df_cleaned.drop(columns=['semester_dropout'], inplace=True)

# Handle identifier columns
X = df_encoded.drop(['flag_peringatan_dini', 'npm', 'nama'], axis=1)
y = df_encoded['flag_peringatan_dini']
```

**B. Categorical Encoding:**
```python
# Label Encoding for categorical variables
le = LabelEncoder()
columns_to_encode = [
    'jenis_kelamin', 'penghasilan_keluarga', 'status_pekerjaan',
    'asal_daerah', 'jenis_sma', 'kategori_risiko', 
    'status_saat_ini', 'rekomendasi_intervensi'
]

for col in columns_to_encode:
    df_encoded[col] = le.fit_transform(df_encoded[col])
```

**C. Data Splitting:**
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
# Result: Train=228, Test=57 samples
```

### **Phase 4: Modeling**

**Multi-Algorithm Approach:**
```python
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    "XGBoost": XGBClassifier(eval_metric='logloss', random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(n_neighbors=10),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "AdaBoost": AdaBoostClassifier(random_state=42)
}

# Training Pipeline
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model
```

### **Phase 5: Evaluation**

**Comprehensive Evaluation:**
```python
# Multi-metric evaluation
for name, model in trained_models.items():
    y_pred = model.predict(X_test)
    
    metrics = {
        "accuracy": accuracy_score(y_test, y_pred),
        "precision": precision_score(y_test, y_pred, average='weighted'),
        "recall": recall_score(y_test, y_pred, average='weighted'),
        "f1_score": f1_score(y_test, y_pred, average='weighted'),
        "confusion_matrix": confusion_matrix(y_test, y_pred)
    }
```

### **Phase 6: Deployment**

**Model Persistence:**
```python
# Save best performing models
save_dir = 'Menyimpan_Model'
for name, model in trained_models.items():
    filename = f'model_{name.replace(" ", "_")}.pkl'
    joblib.dump(model, os.path.join(save_dir, filename))

# Save preprocessing tools
joblib.dump(scaler, 'scaler.pkl')
joblib.dump(feature_list, 'fitur_model.pkl')
```

---

## Teknik Preprocessing Data

### **1. Data Quality Assessment**

**Cerita Assessment:**
Sebelum masak, chef selalu mengecek kualitas bahan. Begitu pula dengan data - kita perlu memastikan tidak ada "bahan rusak" yang bisa merusak model.

```python
# Missing Values Analysis
missing_analysis = df.isnull().sum()
missing_percentage = (missing_analysis / len(df)) * 100

print("Data Quality Report:")
print(f"Total Records: {len(df)}")
print(f"Duplicates: {df.duplicated().sum()}")
print(f"Missing Values: {missing_analysis.sum()}")
```

**Hasil Assessment:**
- **Kualitas Excellent**: 0 duplikasi, minimal missing values
- **semester_dropout**: 98.6% missing (normal - mahasiswa aktif)
- **Semua fitur penting**: Lengkap tanpa missing values

### **2. Categorical Data Encoding**

**Teknik Label Encoding:**
```python
# Strategic encoding untuk 8 variabel kategorik
encoding_mapping = {
    'jenis_kelamin': {'L': 1, 'P': 0},
    'penghasilan_keluarga': {'Rendah': 0, 'Menengah': 1, 'Tinggi': 2},
    'status_pekerjaan': {'Tidak Bekerja': 0, 'Part-time': 1, 'Full-time': 2},
    'asal_daerah': {'Dalam Kota': 0, 'Luar Kota': 1},
    'jenis_sma': {'SMK': 0, 'SMA Negeri': 1, 'SMA Swasta': 2, 'MA': 3}
}

# Automated encoding
for col in columns_to_encode:
    df_encoded[col] = le.fit_transform(df_encoded[col])
```

### **3. Feature Scaling & Normalization**

**StandardScaler Implementation:**
```python
# Standardization untuk konsistensi skala
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Hasil: Mean ‚âà 0, Std ‚âà 1 untuk semua fitur numerik
```

**Justifikasi StandardScaler:**
- **Konsistensi Skala**: IPK (0-4) vs Total Jam LMS (0-1000) distandardisasi
- **Algorithm Compatibility**: Random Forest toleran, tapi KNN & SVM memerlukan scaling
- **Convergence Speed**: Mempercepat training untuk gradient-based algorithms

### **4. Feature Engineering**

**Derived Features:**
```python
# Fitur yang sudah ter-engineer dalam dataset:
engineering_features = {
    'konsistensi_kehadiran': 'Variabilitas pola kehadiran',
    'trend_ipk': 'Slope perubahan IPK dari semester ke semester',
    'rata_jam_lms_per_semester': 'Normalisasi aktivitas LMS',
    'skor_risiko': 'Composite risk score dari multiple factors'
}
```

---

## Strategi Evaluasi Model

### **1. Multi-Metric Evaluation Framework**

**Cerita Evaluasi:**
Seperti menilai performa atlet dari berbagai aspek (kecepatan, kekuatan, daya tahan), model ML juga dievaluasi dari multiple dimensi untuk memastikan performa yang balanced.

```python
# Comprehensive evaluation metrics
evaluation_metrics = {
    'accuracy': 'Overall correctness rate',
    'precision': 'True positive rate (avoid false alarms)',
    'recall': 'Sensitivity to detect actual dropout risk',
    'f1_score': 'Harmonic mean of precision and recall',
    'confusion_matrix': 'Detailed classification breakdown'
}
```

### **2. Hasil Evaluasi Komprehensif**

| Model | Accuracy | Precision | Recall | F1-Score | Keterangan |
|-------|----------|-----------|---------|----------|------------|
| **Random Forest** | **100.00%** | **100.00%** | **100.00%** | **100.00%** | **Perfect Classification** |
| AdaBoost | 98.25% | 98.31% | 98.25% | 98.25% | Excellent Performance |
| XGBoost | 94.74% | 95.28% | 94.74% | 94.75% | Very Good |
| Decision Tree | 94.74% | 95.28% | 94.74% | 94.75% | Good but prone to overfitting |
| Gradient Boosting | 94.74% | 95.28% | 94.74% | 94.75% | Solid performance |
| K-NN | 75.44% | 77.06% | 75.44% | 74.61% | Acceptable |

### **3. Confusion Matrix Analysis**

```python
# Visualisasi detailed performance per model
for idx, (name, metrics) in enumerate(results.items()):
    sns.heatmap(metrics["Confusion Matrix"], annot=True, fmt="d", 
                cmap="Blues", ax=axes[idx])
    axes[idx].set_title(f"Confusion Matrix - {name}")
```

### **4. Model Selection Criteria**

**Decision Framework:**
1. **Primary**: Accuracy ‚â• 95% (Critical untuk early warning)
2. **Secondary**: Balanced Precision & Recall (Minimize false negatives)
3. **Tertiary**: Computational Efficiency (Real-time deployment)
4. **Quaternary**: Interpretability (Stakeholder understanding)

**Winner: Random Forest**
- ‚úÖ Perfect accuracy (100%)
- ‚úÖ Zero false negatives (critical untuk dropout prevention)
- ‚úÖ Fast prediction (<100ms)
- ‚úÖ Feature importance interpretability

---

## Struktur Project

```
UAS_DATA_MINING/
‚îÇ
‚îú‚îÄ‚îÄ README.md                              # Dokumentasi komprehensif
‚îú‚îÄ‚îÄ dataset_prediksi_dropout_TI_2022_2024.csv  # Dataset original (285 records)
‚îú‚îÄ‚îÄ UAS_DATA_MINING(MODELLINGV2).ipynb    # Notebook utama CRISP-DM
‚îú‚îÄ‚îÄ customize_dataset.ipynb               # Data exploration & customization
‚îÇ
‚îú‚îÄ‚îÄ Dataset_Clean/                        # Processed datasets
‚îÇ   ‚îú‚îÄ‚îÄ df_cleaned.csv                   # Clean dataset (drop irrelevant cols)
‚îÇ   ‚îî‚îÄ‚îÄ df_encoded.csv                   # Encoded categorical variables
‚îÇ
‚îú‚îÄ‚îÄ Menyimpan_Model/                     # Saved models & tools
‚îÇ   ‚îú‚îÄ‚îÄ model_Random_Forest.pkl         # Best model (100% accuracy)
‚îÇ   ‚îú‚îÄ‚îÄ model_XGBoost.pkl              # Backup model
‚îÇ   ‚îú‚îÄ‚îÄ model_Decision_Tree.pkl        # Alternative model
‚îÇ   ‚îú‚îÄ‚îÄ model_Gradient_Boosting.pkl    # Ensemble alternative
‚îÇ   ‚îú‚îÄ‚îÄ model_AdaBoost.pkl             # Sequential learner
‚îÇ   ‚îú‚îÄ‚îÄ model_K_Nearest_Neighbors.pkl  # Instance-based learner
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl                     # StandardScaler for preprocessing
‚îÇ   ‚îî‚îÄ‚îÄ fitur_model.pkl               # Feature list for consistency
‚îÇ
‚îî‚îÄ‚îÄ Dashboard_Implementation/           # Production deployment
```

---

## Instalasi dan Setup

### 1. Environment Setup
```bash
# Clone project
git clone [repository-url]
cd UAS_DATA_MINING

# Create virtual environment
python -m venv dropout_prediction_env
source dropout_prediction_env/bin/activate  # Linux/Mac
# dropout_prediction_env\Scripts\activate   # Windows
```

### 2. Dependencies Installation
```bash
# Install required packages
pip install tensorflow==2.15.0 tf-keras==2.15.1 keras==2.15.0 \
    numpy==1.26.4 protobuf==4.25.7 h5py==3.13.0 pandas==2.2.2 \
    scikit-learn==1.6.1 keras-tuner==1.4.7 matplotlib==3.10.3 \
    seaborn==0.13.2 xgboost scipy imbalanced-learn joblib \
    streamlit plotly --upgrade --no-cache-dir

# Verify installation
python -c "import pandas, sklearn, xgboost; print('Setup successful!')"
```

### 3. Data Verification
```python
import pandas as pd
df = pd.read_csv('dataset_prediksi_dropout_TI_2022_2024.csv')
print(f"Dataset loaded: {len(df)} records, {len(df.columns)} features")
```

---

## Penggunaan Sistem

### 1. Training Pipeline (Full CRISP-DM)
```python
# Execute complete pipeline
jupyter notebook UAS_DATA_MINING(MODELLINGV2).ipynb

# Step-by-step execution:
# 1. Business Understanding & Data Loading
# 2. Exploratory Data Analysis
# 3. Data Preprocessing & Feature Engineering
# 4. Multi-Algorithm Training & Comparison
# 5. Model Evaluation & Selection
# 6. Model Persistence & Deployment Preparation
```

### 2. Real-time Prediction Interface
```python
import pandas as pd
import joblib

# === LOAD PRODUCTION MODELS ===
model = joblib.load('./Menyimpan_Model/model_Random_Forest.pkl')
scaler = joblib.load('./Menyimpan_Model/scaler.pkl')
fitur = joblib.load('./Menyimpan_Model/fitur_model.pkl')

# === INTERACTIVE PREDICTION SYSTEM ===
def predict_student_dropout():
    print("=== SISTEM PREDIKSI DROPOUT MAHASISWA ===\n")
    
    # Data collection
    student_data = {}
    student_data['angkatan'] = int(input("Angkatan (2022-2024): "))
    student_data['semester_saat_ini'] = int(input("Semester saat ini (1-8): "))
    student_data['jenis_kelamin'] = int(input("Jenis kelamin (0=Perempuan, 1=Laki-laki): "))
    student_data['usia'] = int(input("Usia (19-25): "))
    student_data['penghasilan_keluarga'] = int(input("Penghasilan keluarga (0=Rendah, 1=Menengah, 2=Tinggi): "))
    student_data['beasiswa'] = int(input("Beasiswa (0=Tidak, 1=Ya): "))
    student_data['status_pekerjaan'] = int(input("Status pekerjaan (0=Tidak Bekerja, 1=Part-time, 2=Full-time): "))
    student_data['asal_daerah'] = int(input("Asal daerah (0=Dalam Kota, 1=Luar Kota): "))
    student_data['jenis_sma'] = int(input("Jenis SMA (0=SMK, 1=SMA Negeri, 2=SMA Swasta, 3=MA): "))
    student_data['skor_masuk'] = float(input("Skor masuk (60-100): "))
    student_data['ipk_rata_rata'] = float(input("IPK rata-rata (0.0-4.0): "))
    student_data['trend_ipk'] = float(input("Trend IPK (-1.0 to +1.0): "))
    student_data['kehadiran_rata_rata'] = float(input("Kehadiran rata-rata (0-100%): "))
    student_data['konsistensi_kehadiran'] = float(input("Konsistensi kehadiran (0-20): "))
    student_data['total_jam_lms'] = int(input("Total jam aktivitas di LMS: "))
    student_data['rata_jam_lms_per_semester'] = float(input("Rata-rata jam LMS per semester: "))
    student_data['total_mengulang'] = int(input("Total mata kuliah yang diulang: "))
    student_data['skor_risiko'] = int(input("Skor risiko (0-10): "))
    
    # Data preprocessing
    for col in fitur:
        if col not in student_data:
            student_data[col] = 0
    
    # Prediction pipeline
    df_input = pd.DataFrame([student_data])[fitur]
    df_scaled = scaler.transform(df_input)
    
    # Generate prediction & probability
    prediction = model.predict(df_scaled)[0]
    probability = model.predict_proba(df_scaled)[0]
    confidence = max(probability) * 100
    
    # Results display
    risk_category = "üö® BERISIKO DROPOUT" if prediction == 1 else "‚úÖ AMAN"
    print(f"\n{'='*50}")
    print(f"HASIL PREDIKSI: {risk_category}")
    print(f"Confidence Level: {confidence:.1f}%")
    print(f"{'='*50}")
    
    # Personalized intervention recommendations
    if prediction == 1:
        interventions = []
        
        if student_data['ipk_rata_rata'] < 2.5:
            interventions.append("üìö Program Bimbingan Akademik Intensif")
        
        if student_data['penghasilan_keluarga'] == 0 and student_data['beasiswa'] == 0:
            interventions.append("üí∞ Bantuan Finansial & Pengajuan Beasiswa")
        
        if student_data['kehadiran_rata_rata'] < 75:
            interventions.append("üìÖ Monitoring Kehadiran & Konseling Motivasi")
        
        if student_data['total_jam_lms'] < 200:
            interventions.append("üíª Program Peningkatan Engagement Digital")
        
        if not interventions:
            interventions.append("üìä Monitoring Rutin & Evaluasi Berkala")
        
        print("\nüéØ REKOMENDASI INTERVENSI:")
        for i, intervention in enumerate(interventions, 1):
            print(f"   {i}. {intervention}")
    else:
        print("\n‚ú® Mahasiswa dalam kategori AMAN.")
        print("   Lanjutkan monitoring berkala dan maintain performa.")
    
    return prediction, confidence

# Run prediction
predict_student_dropout()
```

### 3. Batch Prediction untuk Multiple Students
```python
def batch_predict_dropout(csv_file_path):
    """Prediksi batch untuk multiple mahasiswa"""
    
    # Load batch data
    df_batch = pd.read_csv(csv_file_path)
    
    # Preprocessing
    df_processed = preprocess_batch_data(df_batch)
    
    # Predictions
    predictions = model.predict(df_processed)
    probabilities = model.predict_proba(df_processed)
    
    # Results compilation
    results = pd.DataFrame({
        'npm': df_batch['npm'],
        'nama': df_batch['nama'],
        'prediction': predictions,
        'risk_probability': probabilities[:, 1],
        'risk_category': ['High Risk' if p == 1 else 'Safe' for p in predictions]
    })
    
    return results.sort_values('risk_probability', ascending=False)
```

---

## Pengembangan Sistem Lanjutan

### **1. Dashboard Interaktif untuk Rektorat**

**Cerita Visi Dashboard:**
Rektor dapat memonitor kondisi seluruh mahasiswa dalam satu layar dashboard komprehensif. Visualisasi real-time menampilkan tren dropout, distribusi risiko per angkatan, dan efektivitas program intervensi yang sedang berjalan.

**Konsep Fitur Dashboard:**
- **Executive Summary**: KPI utama seperti total mahasiswa berisiko, tingkat retensi, dan ROI program intervensi
- **Risk Heat Map**: Visualisasi geografis sebaran mahasiswa berisiko berdasarkan asal daerah
- **Trend Analytics**: Grafik prediktif untuk 4 semester ke depan dengan confidence interval
- **Intervention Tracking**: Monitor progress setiap program bantuan yang sedang berjalan
- **Comparative Analysis**: Benchmarking dengan program studi lain atau universitas sejenis

**Link Dashboard Prototipe:** http://KillerKing93-UAS-Penambangan-Data.hf.space
- Username: admin
- Password: admin123

### **2. Integrasi dengan Sistem Informasi Akademik (SIAKAD)**

**Konsep Integrasi Seamless:**
Sistem prediksi terintegrasi langsung dengan SIAKAD melalui RESTful API, memungkinkan update otomatis data mahasiswa dan trigger prediksi real-time setiap kali ada perubahan data akademik.

**Rencana Integrasi:**
- **Automated Data Pipeline**: Sinkronisasi harian data mahasiswa dari SIAKAD ke sistem prediksi
- **Real-time Prediction**: Trigger prediksi otomatis saat input nilai, kehadiran, atau data finansial
- **Bi-directional Communication**: SIAKAD menerima hasil prediksi dan rekomendasi intervensi
- **Single Sign-On (SSO)**: Integrasi autentikasi untuk akses seamless antar sistem
- **Audit Trail**: Logging semua aktivitas prediksi untuk compliance dan monitoring

### **3. Mobile Application Ecosystem**

**Aplikasi Multi-Platform:**

**A. Student Self-Monitoring App:**
- Dashboard personal untuk melihat risk score dan trend akademik
- Self-assessment tools untuk evaluasi diri berkala
- Push notifications untuk reminder deadline dan aktivitas penting
- Akses ke resource akademik dan bantuan finansial
- Peer support network dan study group finder

**B. Faculty Monitoring App:**
- Real-time monitoring mahasiswa bimbingan dengan risk alerts
- Interface untuk input observasi dan feedback mahasiswa
- Quick intervention tools untuk immediate response
- Progress tracking students under intervention programs
- Communication hub dengan tim akademik

**C. Administrative Staff App:**
- Bulk prediction tools untuk batch processing
- Intervention program management dan tracking
- Resource allocation planning berdasarkan prediction results
- Report generation untuk stakeholder meetings

### **4. Advanced Analytics & Machine Learning Evolution**

**Roadmap Pengembangan ML:**

**A. Ensemble Learning Enhancement:**
- Kombinasi Random Forest, XGBoost, dan Neural Networks dengan weighted voting
- Adaptive ensemble yang otomatis menyesuaikan bobot berdasarkan performa real-time
- Meta-learning untuk optimasi hyperparameter otomatis

**B. Deep Learning Integration:**
- Recurrent Neural Networks (RNN/LSTM) untuk analisis sequential data akademik
- Convolutional Neural Networks untuk pattern recognition dalam learning behavior
- Transformer architecture untuk natural language processing dari feedback text

**C. Predictive Analytics Expansion:**
- Time series forecasting untuk prediksi tren dropout institutional level
- Survival analysis untuk estimasi "time-to-dropout" per mahasiswa
- Causal inference untuk mengidentifikasi faktor intervention yang paling efektif

### **5. Real-time Monitoring & Alert System**

**Intelligent Early Warning System:**

**Konsep Sistem Alert Bertingkat:**
- **Level 1 (Green)**: Monitoring rutin mingguan dengan automated reports
- **Level 2 (Yellow)**: Alert untuk risk score increase >15% dalam 2 minggu
- **Level 3 (Orange)**: Immediate notification untuk risk >70% dengan intervention recommendation
- **Level 4 (Red)**: Emergency protocol untuk extreme risk cases dengan direct counselor assignment

**Multi-Channel Notification:**
- Email alerts untuk academic staff dengan detailed student profiles
- SMS notifications untuk urgent cases requiring immediate action
- WhatsApp integration untuk informal communication dengan mahasiswa
- Slack/Teams integration untuk internal coordination tim akademik

### **6. Personalized Intervention Framework**

**Adaptive Intervention Engine:**

**Strategi Personalisasi Berdasarkan Profil:**
- **Academic Strugglers**: Tutoring programs, study skills workshops, alternative learning methods
- **Financial Hardship**: Scholarship assistance, work-study programs, emergency financial aid
- **Social Isolation**: Peer mentoring, extracurricular engagement, counseling services
- **Career Uncertainty**: Industry mentorship, internship programs, career counseling
- **Personal Issues**: Mental health support, family counseling, flexible academic arrangements

**Intervention Effectiveness Tracking:**
- A/B testing untuk membandingkan efektivitas berbagai jenis intervensi
- Longitudinal analysis untuk mengukur dampak jangka panjang program bantuan
- Cost-effectiveness analysis untuk optimasi alokasi sumber daya intervention
- Continuous improvement cycle berdasarkan feedback dan outcomes data

### **7. Ecosystem Integration & Expansion**

**Learning Management System (LMS) Integration:**
- Automated extraction of engagement metrics dari Moodle/Canvas/Google Classroom
- Real-time activity monitoring untuk early detection of disengagement
- Integration dengan discussion forums untuk sentiment analysis
- Assignment submission pattern analysis untuk academic behavior prediction

**External Data Sources Integration:**
- Social media sentiment analysis (dengan persetujuan mahasiswa) untuk mental health indicators
- Transportation data integration untuk commuter students risk assessment
- Local economic indicators untuk correlation dengan financial stress patterns
- Weather data correlation dengan attendance dan academic performance

**Multi-Institutional Collaboration:**
- Benchmarking platform dengan universitas lain untuk best practices sharing
- Federated learning approach untuk model improvement tanpa sharing sensitive data
- Industry partnership untuk real-world outcome tracking (employment, career success)
- Government collaboration untuk national education policy insights

### **8. Sustainability & Scalability Framework**

**Technical Scalability:**
- Cloud-native architecture untuk horizontal scaling
- Microservices design untuk modular development dan maintenance
- API-first approach untuk easy integration dengan sistem baru
- Event-driven architecture untuk real-time processing capabilities

**Organizational Scalability:**
- Change management strategy untuk adoption di program studi lain
- Training programs untuk faculty dan staff dalam menggunakan sistem
- Standard operating procedures untuk intervention protocols
- Quality assurance framework untuk maintaining prediction accuracy

**Financial Sustainability:**
- Cost-benefit analysis model untuk justifikasi investasi berkelanjutan
- Revenue sharing model dengan universitas lain untuk commercialization
- Grant application strategy untuk research funding
- Partnership dengan edtech companies untuk technology advancement

### **Timeline Implementasi (24 Bulan)**

**Phase 1 (Bulan 1-6): Foundation**
- Dashboard development dan SIAKAD integration
- Mobile app MVP untuk students dan faculty
- Basic real-time monitoring implementation

**Phase 2 (Bulan 7-12): Enhancement**
- Advanced analytics integration (ensemble learning, deep learning)
- LMS integration dan external data sources
- Comprehensive intervention framework deployment

**Phase 3 (Bulan 13-18): Optimization**
- AI/ML model refinement berdasarkan real-world data
- Advanced personalization features
- Multi-institutional collaboration initiation

**Phase 4 (Bulan 19-24): Expansion**
- Full ecosystem integration dan automation
- Scalability testing dan optimization
- Commercialization strategy development

### **Expected Impact & ROI**

**Quantitative Targets:**
- Dropout rate reduction: 52.6% ‚Üí 25% dalam 2 tahun
- Early intervention success rate: >80%
- Student satisfaction increase: 20-25%
- Faculty efficiency improvement: 35%
- Cost savings: Rp 3.5 miliar/tahun dari reduced dropout

**Qualitative Benefits:**
- Enhanced institutional reputation dan accreditation score
- Improved student mental health dan well-being
- Data-driven decision making culture dalam institusi
- Research opportunities dan publication potential
- Industry recognition sebagai innovative educational institution

Sistem ini merepresentasikan transformasi digital komprehensif dalam manajemen mahasiswa, dari reactive approach menjadi proactive, predictive, dan personalized student success ecosystem.
